README.md
ğŸ§ Taller â€” Desarrollo en Contenedores (API + Jupyter + uv + Compose)

Este proyecto expone una API FastAPI que clasifica especies de pingÃ¼inos (Palmer Penguins) y un entorno de JupyterLab para entrenar y guardar nuevos modelos. Ambos servicios comparten un volumen de modelos; asÃ­, cuando el notebook guarda un modelo nuevo, la API puede recargar esos artefactos sin reiniciar el contenedor.

Arquitectura

```bash
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        volumen compartido         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   JupyterLab    â”‚  /workspace/models  <â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚     API        â”‚
â”‚  (entrenamiento)â”‚                                   â”‚ (inferencias) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â–²                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                guarda artefactos
```

JupyterLab: entrena y guarda logistic_regression_model.pkl, scaler.pkl, model_info.json en el volumen compartido.

API (FastAPI): sirve predicciones; puede recargar los artefactos con POST /model/reload sin reiniciar.

ğŸ“ Estructura relevante

```graphql
.
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                 # FastAPI: endpoints de predicciÃ³n, health, info y /model/reload
â”‚   â””â”€â”€ schemas.py              # Pydantic (v2) - incluye campo "year" y nombres correctos sex_female/sex_male
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing.py      # Pipeline de procesamiento (palmerpenguins + limpieza + OHE)
â”‚   â”œâ”€â”€ model_training.py       # Entrenamiento, evaluaciÃ³n, metadata
â”‚   â””â”€â”€ model_manager.py        # Carga/guardado/validaciÃ³n de artefactos
â”œâ”€â”€ train_model.py              # Script maestro: procesa â†’ entrena â†’ guarda artefactos
â”œâ”€â”€ requirements.txt            # Dependencias; se instalan con uv en los contenedores
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.api          # Imagen API con uv
â”‚   â””â”€â”€ Dockerfile.jupyter      # Imagen JupyterLab con uv
â””â”€â”€ docker-compose.yml          # OrquestaciÃ³n: servicios + volumen compartido de modelos
```

ğŸ”Œ Endpoints principales

GET / â€“ info bÃ¡sica del servicio

GET /health â€“ estado (incluye si modelo/scaler estÃ¡n cargados)

GET /model/info â€“ tipo de modelo, versiÃ³n, features, mÃ©tricas

POST /predict/simple â€“ recibe entrada â€œhumanaâ€ y hace el encode internamente

Importante: incluye year (int) y sex con valores "Male"/"Female".

POST /predict/complete â€“ entrada ya one-hot

POST /model/reload â€“ recarga artefactos desde MODELS_DIR (volumen compartido)

Swagger UI: http://localhost:8989/docs
ReDoc: http://localhost:8989/redoc

ğŸ§© Variables de entorno relevantes

MODELS_DIR

En API: /app/models

En Jupyter: /workspace/models

Ambos apuntan al mismo volumen (model_store) para compartir artefactos.

ğŸ› ï¸ Requisitos previos

Docker Desktop en Windows con WSL2 backend habilitado.

WSL Ubuntu configurado (usas la terminal de Ubuntu para los comandos).

Puertos libres:

8989 para la API

8888 para Jupyter

ğŸš€ Puesta en marcha

Desde la raÃ­z del proyecto (donde estÃ¡ docker-compose.yml):

```bash
docker compose down -v          # opcional: limpiar
docker compose build            # construye imÃ¡genes de API y Jupyter
docker compose up -d            # levanta ambos servicios en segundo plano
docker compose logs -f api      # ver logs de API
docker compose logs -f jupyter  # ver logs de Jupyter

```

Abre Jupyter: http://localhost:8888
(Se ejecuta sin token y como root solo para desarrollo local; si quieres, configura seguridad mÃ¡s adelante.)

Abre la API: http://localhost:8989/docs

ğŸ§ª Flujos de prueba
1) Entrenar un modelo desde Jupyter

En un notebook de Jupyter (p. ej. notebooks/train_penguins.ipynb), ejecuta:

```python
!python train_model.py
```
Esto:

Procesa datos â†’ entrena â†’ guarda artefactos en /workspace/models (volumen compartido).

Verifica artefactos:
```bash
!ls -lh /workspace/models

```
DeberÃ­as ver:

```pgsql
logistic_regression_model.pkl
scaler.pkl
model_info.json
```

ğŸ§‘â€ğŸ’» Desarrollo con VS Code (WSL)

Abre la carpeta del proyecto en VS Code (WSL).

Edita archivos Python: el contenedor de la API monta ./ en /app, y Uvicorn estÃ¡ con --reload, asÃ­ que las rutas vivas recargan automÃ¡ticamente.

Si cambias requirements.txt o Dockerfiles:

```bash
docker compose build api && docker compose restart api
# o para Jupyter:
docker compose build jupyter && docker compose restart jupyter

```
ğŸ§¯ Troubleshooting

Jupyter se cierra con â€œRunning as root is not recommendedâ€: ya estÃ¡ mitigado con --allow-root en Compose.

Puerto 8989 ocupado:
```bash
sudo lsof -i:8989
kill -9 <PID>

```
/docs no carga: usa /docs (no /doc).

/model/reload no aparece: asegÃºrate de haber guardado cambios de api/main.py y que Uvicorn hizo reload (o reinicia el servicio API).

ğŸ”® PrÃ³ximos pasos:

Crear un notebook de entrenamiento (notebooks/train_penguins.ipynb) que:

Procese datos con src.data_processing.

Entrene con src.model_training.

Guarde artefactos con src.model_manager dentro del volumen compartido.

Desde ese notebook, hacer un POST a http://api:8989/model/reload (o http://localhost:8989 si prefieres) para recargar el modelo.

Validar predicciones llamando a /predict/simple desde el notebook.

Opcional: agregar celdas para explorar mÃ©tricas del model_info.json.